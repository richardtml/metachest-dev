{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PadChest CSV\n",
    "\n",
    "This notebook generates `padchest.csv` assuming the following are downloaded:\n",
    "\n",
    "* [PadChest](https://bimcv.cipf.es/bimcv-projects/padchest/) dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from common import read_toml\n",
    "from common import AGE_INTERVAL\n",
    "from common import PADCHEST_PATHOLOGIES as PATHOLOGIES\n",
    "\n",
    "UNIQUE_STUDIES = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_toml('config.toml')\n",
    "base_dir = config['padchest_dir']\n",
    "!ls -hs1 {base_dir}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padchest_df_path = join(base_dir, 'PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv.gz')\n",
    "padchest_df = pd.read_csv(padchest_df_path, index_col=0, compression='gzip', low_memory=False)\n",
    "padchest_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with missing attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(padchest_df)\n",
    "padchest_df = padchest_df.dropna(\n",
    "    subset=['Projection',\n",
    "            'PatientSex_DICOM',\n",
    "            'PatientBirth',\n",
    "            'StudyDate_DICOM',\n",
    "            'Labels'])\n",
    "dropped_size = len(padchest_df)\n",
    "print(f'padchest_df size: original {original_size}, new {dropped_size}, dropped {original_size - dropped_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UNIQUE_STUDIES:\n",
    "    padchest_df = padchest_df.groupby('PatientID').first()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build labels df and join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to match with labels df\n",
    "padchest_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "aliases = {\n",
    "    'infiltration': {\n",
    "        'infiltrates',\n",
    "        'interstitial pattern',\n",
    "        'ground glass pattern',\n",
    "        'reticular interstitial pattern',\n",
    "        'reticulonodular interstitial pattern',\n",
    "        'alveolar pattern',\n",
    "        'consolidation',\n",
    "        'air bronchogram'\n",
    "    },\n",
    "    'pleural_thickening' : {\n",
    "        'pleural thickening'\n",
    "    }\n",
    "}\n",
    "\n",
    "labels = {}\n",
    "labels_col = padchest_df['Labels']\n",
    "for pathology in PATHOLOGIES:\n",
    "    mask = labels_col.str.contains(pathology)\n",
    "    pat_aliases = aliases.get(pathology, None)\n",
    "    if pat_aliases:\n",
    "        for pat_alias in pat_aliases:\n",
    "            mask |= labels_col.str.contains(pat_alias)\n",
    "    labels[pathology] = mask.values.astype(int)\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "# join\n",
    "df = pd.concat([padchest_df, labels_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns and filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(df)\n",
    "\n",
    "# rename cols\n",
    "df = df.rename(columns={\n",
    "    'ImageID': 'name',\n",
    "    'Projection': 'view',\n",
    "    'PatientSex_DICOM': 'sex',\n",
    "    'PatientBirth': 'birth_date',\n",
    "    'StudyDate_DICOM': 'study_date'\n",
    "})\n",
    "# keep views\n",
    "print('Available views: ', df.view.unique())\n",
    "df = df[df['view'].isin(['AP', 'PA', 'AP_horizontal'])]\n",
    "# compute age in the study\n",
    "df['age'] = df['study_date'].astype(str).str[:4].astype(int) - df['birth_date'].astype(int)\n",
    "df = df[df['age'].between(*AGE_INTERVAL, inclusive='both')]\n",
    "# keep cols\n",
    "df = df[['name', 'age', 'sex', 'view'] + PATHOLOGIES]\n",
    "# filter out normal\n",
    "df = df[df[PATHOLOGIES].any(axis=1)]\n",
    "\n",
    "# remove image extension\n",
    "df['name'] = df['name'].str[:-4]\n",
    "df['view'] = df['view'].replace('AP_horizontal','ap')\n",
    "df['sex'] = df['sex'].str.lower()\n",
    "df['view'] = df['view'].str.lower()\n",
    "\n",
    "df.insert(0, 'dataset', 'padchest', True)\n",
    "\n",
    "dropped_size = len(df)\n",
    "print(f'df size: original {original_size}, new {dropped_size}, dropped {original_size - dropped_size}')\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing records with wrong labels or corrupted images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_labels = [\n",
    "    '216840111366964012558082906712010102112808556_03-181-172',\n",
    "]\n",
    "corrupted = [\n",
    "    # https://github.com/mlmed/torchxrayvision/blob/7879060cbe0a8172d8f91ddab786ba707fbfa5ec/torchxrayvision/datasets.py#L746\n",
    "    \"216840111366964012819207061112010307142602253_04-014-084\",\n",
    "    \"216840111366964012989926673512011074122523403_00-163-058\",\n",
    "    \"216840111366964012959786098432011033083840143_00-176-115\",\n",
    "    \"216840111366964012558082906712009327122220177_00-102-064\",\n",
    "    \"216840111366964012339356563862009072111404053_00-043-192\",\n",
    "    \"216840111366964013076187734852011291090445391_00-196-188\",\n",
    "    \"216840111366964012373310883942009117084022290_00-064-025\",\n",
    "    \"216840111366964012283393834152009033102258826_00-059-087\",\n",
    "    \"216840111366964012373310883942009170084120009_00-097-074\",\n",
    "    \"216840111366964012819207061112010315104455352_04-024-184\",\n",
    "    \"216840111366964012819207061112010306085429121_04-020-102\",\n",
    "    # truncated\n",
    "    '216840111366964013590140476722013058110301622_02-056-111',\n",
    "    '216840111366964013590140476722013043111952381_02-065-198',\n",
    "    '216840111366964013829543166512013353113303615_02-092-190',\n",
    "    '216840111366964012373310883942009180082307973_00-097-011',\n",
    "]\n",
    "wrong = incorrect_labels + corrupted\n",
    "df = df[~df['name'].isin(wrong)]\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check there are no normal examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(~df[PATHOLOGIES].astype(bool)).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = join(read_toml('config.toml')['metachest_dir'], 'padchest.csv')\n",
    "df.to_csv(path, index=False)\n",
    "path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total: {df.shape[0]}')\n",
    "df[PATHOLOGIES].sum()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
