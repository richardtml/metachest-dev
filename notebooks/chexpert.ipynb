{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CheXpert\n",
    "\n",
    "This notebook generates `chexpert.csv` and `chexpert_nf.csv` assuming the following are downloaded:\n",
    "\n",
    "* [`CheXpert-v1.0.zip`](https://stanfordmlgroup.github.io/competitions/chexpert/) (azcopy is recommended to download)\n",
    "* [`train_cheXbert.csv`](https://stanfordmlgroup.github.io/competitions/chexpert/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "from common import read_toml\n",
    "from common import AGE_INTERVAL\n",
    "from common import CHEX_PATHOLOGIES as PATHOLOGIES\n",
    "\n",
    "\n",
    "UNIQUE_STUDIES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'chexpert'\n",
    "config = read_toml('../config.toml')\n",
    "metachest_dir = config['metachest_dir']\n",
    "base_dir = config[f'{ds_name}_dir']\n",
    "!ls -hs1 {base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = join(base_dir, 'train_cheXbert.csv')\n",
    "train_df = pd.read_csv(train_df_path)\n",
    "train_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = len(train_df)\n",
    "\n",
    "# drop no-finding\n",
    "df = train_df[~(train_df['No Finding'] == 1.0)]\n",
    "df = df.drop(['No Finding'], axis=1)\n",
    "\n",
    "# rename cols\n",
    "df = df.rename(columns={\n",
    "    'Path': 'name',\n",
    "    'Age': 'age',\n",
    "    'Sex': 'sex',\n",
    "    'AP/PA': 'view'\n",
    "})\n",
    "df = df.rename(columns={\n",
    "    'Pleural Effusion': 'Effusion',\n",
    "    'Lung Opacity': 'Lung_opacity',\n",
    "})\n",
    "for pathology in PATHOLOGIES:\n",
    "    df = df.rename(columns={pathology.capitalize(): pathology})\n",
    "\n",
    "# drop recors witrh missing metadata\n",
    "df = df.dropna(subset=['age', 'sex', 'view'])\n",
    "\n",
    "# keep records with at least one patology\n",
    "df = df.fillna(0)\n",
    "df = df.replace(-1.0, 0)\n",
    "df[PATHOLOGIES] = df[PATHOLOGIES].astype(int)\n",
    "\n",
    "# filter columns\n",
    "df = df[['name', 'age', 'sex', 'view'] + PATHOLOGIES]\n",
    "df = df[df['age'].between(*AGE_INTERVAL, inclusive='both')]\n",
    "\n",
    "df['name'] = df['name'].str[14:-4]\n",
    "df['sex'] = df['sex'].str[:1].str.lower()\n",
    "print('Unique views: ', df.view.unique())\n",
    "df['view'] = df['view'].str.lower()\n",
    "df = df[df['view'].isin(['ap', 'pa'])]\n",
    "\n",
    "df.insert(0, 'dataset', 'chexpert', True)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "dropped_size = len(df)\n",
    "print(f'train_df size: original {original_size}, new {dropped_size}, dropped {original_size - dropped_size}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_df = df[df[PATHOLOGIES].any(axis=1)]\n",
    "nf_df = df[~df[PATHOLOGIES].any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'        Total: {df.shape[0]}\\n'\n",
    "    f'With findings: {wf_df.shape[0]:6d}\\n'\n",
    "    f'  No findings: {nf_df.shape[0]:6d}'\n",
    ")\n",
    "df[PATHOLOGIES].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_filepath = join(metachest_dir, f'{ds_name}.csv')\n",
    "wf_df.to_csv(wf_filepath, index=False)\n",
    "wf_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No findings and MTL partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mtl_nf_partition(nf_df, seed=0, mset=(0, 1, 2)):\n",
    "    n_mtrn = 380503\n",
    "    n_mval = 6793\n",
    "    n_mtst = 209198\n",
    "    n_total = n_mtrn + n_mval + n_mtst\n",
    "    pct_mtrn = n_mtrn / n_total\n",
    "    pct_mval = n_mval / n_total\n",
    "    pct_mtst = n_mtst / n_total\n",
    "\n",
    "    nf_df = nf_df.iloc[:, :5]\n",
    "    nf_df = nf_df.sample(frac=1)\n",
    "\n",
    "    n_total = nf_df.shape[0]\n",
    "    n_mtrn = int(n_total * pct_mtrn)\n",
    "    n_mtst = int(n_total * pct_mtst)\n",
    "    n_mval = n_total - (n_mtrn + n_mtst)\n",
    "\n",
    "    mtrn_df = nf_df.iloc[:n_mtrn].copy()\n",
    "    mval_df = nf_df.iloc[n_mtrn:n_mtrn+n_mval].copy()\n",
    "    mtst_df = nf_df.iloc[n_mtrn+n_mval:].copy()\n",
    "    mtrn_df['mset'] = mset[0]\n",
    "    mval_df['mset'] = mset[1]\n",
    "    mtst_df['mset'] = mset[2]\n",
    "\n",
    "    nf_mtl_df = pd.concat([mtrn_df, mval_df, mtst_df])\n",
    "    nf_filepath = join(metachest_dir, f'{ds_name}_nf.csv')\n",
    "    nf_mtl_df.to_csv(nf_filepath, index=False)\n",
    "\n",
    "    final_pct_mtrn = mtrn_df.shape[0] / nf_mtl_df.shape[0]\n",
    "    final_pct_mval = mval_df.shape[0] / nf_mtl_df.shape[0]\n",
    "    final_pct_mtst = mtst_df.shape[0] / nf_mtl_df.shape[0]\n",
    "\n",
    "    print(f'Original: '\n",
    "        f'mtrn={pct_mtrn*100:5.2f}% '\n",
    "        f'mval={pct_mval*100:5.2f}% '\n",
    "        f'mtst={pct_mtst*100:5.2f}%\\n'\n",
    "        f'     New: '\n",
    "        f'mtrn={final_pct_mtrn*100:5.2f}% '\n",
    "        f'mval={final_pct_mval*100:5.2f}% '\n",
    "        f'mtst={final_pct_mtst*100:5.2f}%\\n'\n",
    "        f'     New: '\n",
    "        f'mtrn={mtrn_df.shape[0]} '\n",
    "        f'mval={mval_df.shape[0]} '\n",
    "        f'mtst={mtst_df.shape[0]}'\n",
    "    )\n",
    "\n",
    "    print(f'Saved to {nf_filepath}')\n",
    "\n",
    "\n",
    "generate_mtl_nf_partition(nf_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metachest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
