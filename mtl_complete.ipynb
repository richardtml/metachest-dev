{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Meta-Learning Distribution\n",
    "\n",
    "This notebook generates the complete meta-learning distribution for MetaChest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from common import MCLASSES, filter_msets, read_toml, save_toml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'complete'\n",
    "mclasses = MCLASSES\n",
    "metachest_dir = read_toml('config.toml')['metachest_dir']\n",
    "mtl_dir = join(metachest_dir, 'mtl')\n",
    "\n",
    "df = pd.read_csv(join(metachest_dir, 'metachest.csv'))\n",
    "\n",
    "filter_df = pd.DataFrame(\n",
    "    [[1, 1, 1]] * df.shape[0],\n",
    "    columns=mclasses.keys()\n",
    ")\n",
    "filter_msets(df, filter_df, mclasses)\n",
    "\n",
    "makedirs(join(mtl_dir), exist_ok=True)\n",
    "save_toml(join(mtl_dir, f'{name}.toml'), mclasses)\n",
    "filter_df.to_csv(join(mtl_dir, f'{name}.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total {df.shape[0]}')\n",
    "print(df['dataset'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute total dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by dataset\n",
    "paths = list(df.columns[5:])\n",
    "ds_sum_df = df[['dataset'] + paths].groupby('dataset').sum().astype(int)\n",
    "# sorted pathologies and datasets sseries\n",
    "ds_sum_sr = ds_sum_df.sum(axis=1).sort_values(ascending=False)\n",
    "pt_sum_sr = ds_sum_df.sum(axis=0).sort_values(ascending=False)\n",
    "# sort grouped df\n",
    "ds_sum_df = ds_sum_df.reindex(list(ds_sum_sr.index))\n",
    "ds_sum_df = ds_sum_df[list(pt_sum_sr.index)]\n",
    "\n",
    "# total df\n",
    "total_df = ds_sum_df.copy()\n",
    "total_df.loc[:, 'total'] = total_df.sum(axis=1)\n",
    "total_df.loc['total', :] = total_df.sum(axis=0)\n",
    "total_df = total_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sum_df.T.plot.barh(stacked=True, figsize=(10, 5),\n",
    "                      color=sns.color_palette('deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.T.iloc[::-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrn, mval, mtst = MCLASSES.values()\n",
    "mset = total_df[mtrn + mval + mtst].T\n",
    "mset_vals = ['mtrn'] * len(mtrn) + ['mval'] * len(mval) + ['mtst'] * len(mtst)\n",
    "mset.insert(0, 'mset', mset_vals)\n",
    "mset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mset.groupby('mset', sort=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sum_df.T.plot.barh(stacked=True, figsize=(10, 5),\n",
    "                      color=sns.color_palette('deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sum_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metasets(ds, mclasses, figsize=(8, 5)):\n",
    "    titles = ['Meta-Train (Seen) ', 'Meta-Val (Unseen) ', 'Meta-Test (Unseen) ']\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=len(mclasses), ncols=1, tight_layout=True,\n",
    "        gridspec_kw={'height_ratios': [len(mset) for mset in mclasses]},\n",
    "        figsize=figsize,\n",
    "    )\n",
    "    for mset, title, ax in zip(mclasses, titles, axs):\n",
    "        ds_mset = ds[mset]\n",
    "        cols = {col: col.replace('_', ' ').capitalize() for col in ds_mset.columns}\n",
    "        idxs = {'chexpert': 'CheXpert', 'mimic': 'MIMIC', 'chestxray14': 'ChestX-ray14', 'padchest': 'PadChest'}\n",
    "        ds_mset = ds_mset.rename(columns=cols, index=idxs)\n",
    "        ax = ds_mset.T.plot.barh(stacked=True, width=0.8, ax=ax,\n",
    "                                 color=sns.color_palette('deep'))\n",
    "        ax.set_xticks([],[])\n",
    "        ax.set_title(title, fontsize=10, loc='right', y=1.0, pad=-14)\n",
    "        if 'Test' in title:\n",
    "            ax.legend(loc='lower right', fontsize='small', labelspacing=0.25)\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "        ax.tick_params(axis='y', which='major', labelsize='small')\n",
    "    xticks = [x for x in range(10000, 130001, 10000)]\n",
    "    ax.set_xticks(xticks, [f'{x//10000}k' for x in xticks], fontsize=7)\n",
    "\n",
    "plot_metasets(ds_sum_df, MCLASSES.values())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
